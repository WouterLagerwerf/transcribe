services:
  transcription-server:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: transcription-server
    restart: unless-stopped
    
    deploy:
      resources:
        limits:
          cpus: '12'
          memory: 24G
        reservations:
          cpus: '8'
          memory: 20G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    
    ports:
      - "${HEALTH_CHECK_PORT:-8080}:8080"
      - "${WEBSOCKET_PORT:-8765}:8765"
    
    environment:
      - SERVER_HOST=${SERVER_HOST:-0.0.0.0}
      - HEALTH_CHECK_PORT=${HEALTH_CHECK_PORT:-8080}
      - WEBSOCKET_PORT=${WEBSOCKET_PORT:-8765}
      # Device configuration (GPU by default)
      - DEVICE=cuda
      - COMPUTE_TYPE=${COMPUTE_TYPE:-float16}
      - PROCESSING_THREADS=${PROCESSING_THREADS:-12}
      # Suppress cuDNN warnings
      - CUDNN_LOGINFO_DBG=0
      - CUDNN_LOGDEST_DBG=/dev/null
      # Model configuration
      - MODEL_NAME=${MODEL_NAME:-large}
      - MODEL_PATH=${MODEL_PATH:-.}
      - LANGUAGE=${LANGUAGE:-}
      # VAD configuration
      - USE_VAD=${USE_VAD:-true}
      - VAD_THRESHOLD=${VAD_THRESHOLD:-0.3}
      - VAD_MIN_SILENCE_MS=${VAD_MIN_SILENCE_MS:-500}
      - VAD_SPEECH_PAD_MS=${VAD_SPEECH_PAD_MS:-200}
      - VAD_MAX_SPEECH_MS=${VAD_MAX_SPEECH_MS:-5000}
      # Speaker diarization
      - USE_DIARIZATION=${USE_DIARIZATION:-true}
      
      - ALLOW_UNSAFE_TORCH_LOAD=0
      - USE_DIARIZATION=true
      - USE_ALIGNMENT=true
      # Speaker ID tuning (strict for quality)
      - SPEAKER_SIMILARITY_THRESHOLD=0.55
      - SPEAKER_ENROLLMENT_THRESHOLD=0.60
      - SPEAKER_ENROLLMENT_FLOOR=0.40
      - SPEAKER_CONFIRMATION_COUNT=4
      - SPEAKER_MIN_SEGMENT_DURATION=1.0
      - SPEAKER_LEARNING_RATE=0.20
      - SPEAKER_MIN_ENERGY=0.0015
      # VAD tuning (external pyannote for quality)
      - VAD_METHOD=pyannote
      - VAD_MIN_SILENCE_MS=400
      - VAD_SPEECH_PAD_MS=300
      - VAD_ONSET=0.5
      - VAD_OFFSET=0.36
      - VAD_CHUNK_SIZE=30
      # Alignment model (optional; uses defaults if unset)
      - USE_ALIGNMENT=true
      # Speaker enrollment
      - ENROLLMENT_SIMILARITY_THRESHOLD=${ENROLLMENT_SIMILARITY_THRESHOLD:-0.75}
      - ENROLLMENT_MIN_SEGMENT_DURATION=${ENROLLMENT_MIN_SEGMENT_DURATION:-0.4}
      - ENROLLMENT_LEARNING_RATE=${ENROLLMENT_LEARNING_RATE:-0.25}
      - ENROLLMENT_MIN_CONFIDENCE=${ENROLLMENT_MIN_CONFIDENCE:-0.65}
      - ENROLLMENT_ADAPTIVE_THRESHOLD=${ENROLLMENT_ADAPTIVE_THRESHOLD:-true}
      # Audio processing
      - MAX_SEGMENT_SECONDS=${MAX_SEGMENT_SECONDS:-3600.0}
    
    shm_size: '2gb'
    
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface:rw
      - ~/.cache/torch:/root/.cache/torch:rw
      - transcription-models:/app/models
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s  # GPU loads models faster
    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  transcription-models:
    driver: local